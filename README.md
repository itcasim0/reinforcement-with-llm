# LLM 평가 파이프라인 (강화학습을 곁들인...)
* LLM의 트렌드 속도가 빨라 새로운 모델이 자주 등장합니다.
* 하지만, 새로운 모델이 마냥 좋다고 할 수도 없고 특정 도메인에서는 모델별로 좋음의 기준이 상이합니다.
    * 사내에서는 새로운 모델이 출시된 것을 사용하도록 해두어도, 비전문가 입장에서는 잘 모르기 때문에 대부분 사용하지 않습니다.
    * 도메인별로 적절한 모델을 사용할 수 있도록 해두지만, 새로운 모델이 도메인에 적절한 지 평가하는 것도 개발자에게 피로한 업무입니다.
* 모델을 평가하는 데 있어서는 보통 테스트 데이터셋으로 성능을 비교하지만, 특정 도메인에서는 비용, 레이턴시, 토큰 수 등 평가해야할 요소가 다양합니다.
* 따라서, 새로운 모델과 수집되는 데이터셋을 통해 도메인 별로 평가기준(보상)을 토대로 학습하여, 도메인에 따른 최적의 모델을 선택하도록 합니다. (Optimal Policy)

## 강화학습 설계
* state = (domain, model)
* domain_space = ("code", "math", ...)
* action_space = ("gemma3", "gpt-oss", ...)

## Version
* python==3.12.4

## Install
* 가상환경 만들기
```bash
python -m venv .venv
```

* 환경 싱크 맞추기
```bash
uv sync
```