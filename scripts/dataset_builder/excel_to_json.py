"""
ì—¬ëŸ¬ Excel íŒŒì¼ì„ í•˜ë‚˜ì˜ JSONìœ¼ë¡œ ë³‘í•©
- í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
- êµ­ë¬¸ ì´ˆë¡ í¬í•¨ëœ ë…¼ë¬¸ë§Œ
"""

import pandas as pd
import json
import glob
import os
from datetime import datetime


def extract_paper_info(row):
    """
    ì—‘ì…€ í–‰ì—ì„œ ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ
    """
    
    # ê¸°ë³¸ ì •ë³´
    paper = {}
    
    # ì œëª© (ì—¬ëŸ¬ ì»¬ëŸ¼ëª… ê°€ëŠ¥)
    for col in ['ì œëª©', 'ë…¼ë¬¸ëª…', 'ë…¼ë¬¸ì œëª©', 'title', 'Title']:
        if col in row.index and pd.notna(row[col]):
            paper['title'] = str(row[col]).strip()
            break
    
    # ì €ì
    for col in ['ì €ì', 'ì €ìëª…', 'ì—°êµ¬ì', 'author', 'Author', 'ì œ1ì €ì']:
        if col in row.index and pd.notna(row[col]):
            paper['author'] = str(row[col]).strip()
            break
    
    # ì´ˆë¡ (ê°€ì¥ ì¤‘ìš”!)
    abstract = ""
    for col in ['ì´ˆë¡', 'ìš”ì•½', 'abstract', 'Abstract', 'êµ­ë¬¸ì´ˆë¡', 'êµ­ë¬¸ ì´ˆë¡', 'í•œê¸€ì´ˆë¡']:
        if col in row.index and pd.notna(row[col]):
            abstract = str(row[col]).strip()
            if len(abstract) > 50:  # ì¶©ë¶„íˆ ê¸´ ì´ˆë¡ë§Œ
                paper['abstract'] = abstract
                break
    
    # ë°œí–‰ë…„ë„
    for col in ['ë°œí–‰ë…„ë„', 'ë…„ë„', 'ë°œê°„ë…„ë„', 'year', 'Year', 'ì¶œíŒë…„ë„']:
        if col in row.index and pd.notna(row[col]):
            try:
                year = int(row[col])
                paper['year'] = year
                break
            except:
                # "2024ë…„" ê°™ì€ í˜•ì‹ ì²˜ë¦¬
                import re
                year_match = re.search(r'(\d{4})', str(row[col]))
                if year_match:
                    paper['year'] = int(year_match.group(1))
                break
    
    # í•™ìˆ ì§€ëª…
    for col in ['í•™ìˆ ì§€ëª…', 'í•™ìˆ ì§€', 'ì €ë„', 'journal', 'Journal', 'ê²Œì¬ì§€']:
        if col in row.index and pd.notna(row[col]):
            paper['journal'] = str(row[col]).strip()
            break
    
    # DOI
    for col in ['DOI', 'doi']:
        if col in row.index and pd.notna(row[col]):
            paper['doi'] = str(row[col]).strip()
            break
    
    # í‚¤ì›Œë“œ
    for col in ['í‚¤ì›Œë“œ', 'keyword', 'Keyword', 'keywords', 'í•µì‹¬ì–´']:
        if col in row.index and pd.notna(row[col]):
            paper['keywords'] = str(row[col]).strip()
            break
    
    return paper


def process_excel_files(folder_path=".", output_file="papers_merged.json"):
    """
    í´ë” ë‚´ ëª¨ë“  Excel íŒŒì¼ ì²˜ë¦¬
    
    Args:
        folder_path: Excel íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”
        output_file: ì¶œë ¥ JSON íŒŒì¼ëª…
    """
    
    print("="*70)
    print("ğŸ“Š Excel â†’ JSON ë³€í™˜ê¸°")
    print("="*70)
    print()
    
    # Excel íŒŒì¼ ì°¾ê¸°
    excel_files = []
    for pattern in ['*.xlsx', '*.xls', '*.csv']:
        excel_files.extend(glob.glob(os.path.join(folder_path, pattern)))
    
    if not excel_files:
        print("âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   í´ë”: {os.path.abspath(folder_path)}")
        return
    
    print(f"ğŸ“ {len(excel_files)}ê°œ íŒŒì¼ ë°œê²¬:")
    for f in excel_files:
        print(f"   - {os.path.basename(f)}")
    print()
    
    # ëª¨ë“  ë…¼ë¬¸ ì €ì¥
    all_papers = []
    stats = {
        'total_rows': 0,
        'with_abstract': 0,
        'without_abstract': 0,
        'files_processed': 0
    }
    
    # ê° íŒŒì¼ ì²˜ë¦¬
    for file_path in excel_files:
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {os.path.basename(file_path)}")
        
        try:
            # íŒŒì¼ ì½ê¸°
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path, encoding='utf-8-sig')
            elif file_path.endswith('.xls'):
                # .xls íŒŒì¼ì€ xlrd ëŒ€ì‹  openpyxl ì‚¬ìš©
                try:
                    df = pd.read_excel(file_path, engine='openpyxl')
                except:
                    # openpyxl ì‹¤íŒ¨ì‹œ xlrd ì‹œë„
                    try:
                        df = pd.read_excel(file_path, engine='xlrd')
                    except:
                        # ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ pyxlsb ì‹œë„
                        df = pd.read_excel(file_path, engine='pyxlsb')
            else:
                df = pd.read_excel(file_path)
            
            print(f"   âœ“ {len(df)}ê°œ í–‰ ë¡œë“œ")
            print(f"   âœ“ ì»¬ëŸ¼: {', '.join(df.columns[:5])}..." if len(df.columns) > 5 else f"   âœ“ ì»¬ëŸ¼: {', '.join(df.columns)}")
            
            # ê° í–‰ ì²˜ë¦¬
            file_papers = []
            for idx, row in df.iterrows():
                stats['total_rows'] += 1
                
                paper = extract_paper_info(row)
                
                # ì´ˆë¡ì´ ìˆëŠ” ë…¼ë¬¸ë§Œ
                if 'abstract' in paper and len(paper.get('abstract', '')) > 50:
                    # ì œëª©ë„ ìˆì–´ì•¼ í•¨
                    if 'title' in paper and len(paper.get('title', '')) > 5:
                        paper['source_file'] = os.path.basename(file_path)
                        file_papers.append(paper)
                        stats['with_abstract'] += 1
                    else:
                        stats['without_abstract'] += 1
                else:
                    stats['without_abstract'] += 1
            
            all_papers.extend(file_papers)
            stats['files_processed'] += 1
            
            print(f"   âœ“ {len(file_papers)}ê°œ ë…¼ë¬¸ ì¶”ì¶œ (ì´ˆë¡ í¬í•¨)\n")
            
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}\n")
            continue
    
    # í†µê³„
    print("="*70)
    print("ğŸ“Š ë³€í™˜ ê²°ê³¼")
    print("="*70)
    print(f"  ì²˜ë¦¬ëœ íŒŒì¼: {stats['files_processed']}ê°œ")
    print(f"  ì´ í–‰ ìˆ˜: {stats['total_rows']}ê°œ")
    print(f"  ì´ˆë¡ ìˆìŒ: {stats['with_abstract']}ê°œ âœ“")
    print(f"  ì´ˆë¡ ì—†ìŒ: {stats['without_abstract']}ê°œ âœ—")
    print()
    
    if not all_papers:
        print("âš ï¸  ë³€í™˜ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ì—°ë„ë³„ í†µê³„
    years = {}
    for p in all_papers:
        year = p.get('year', 0)
        if year > 0:
            years[year] = years.get(year, 0) + 1
    
    if years:
        print("ğŸ“… ì—°ë„ë³„ ë¶„í¬:")
        for year in sorted(years.keys(), reverse=True):
            print(f"   {year}ë…„: {years[year]}ê°œ")
        print()
    
    # JSON ì €ì¥
    output = {
        'metadata': {
            'total_papers': len(all_papers),
            'source_files': [os.path.basename(f) for f in excel_files],
            'conversion_date': datetime.now().isoformat(),
            'years': years
        },
        'papers': all_papers
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
    print(f"   ì´ {len(all_papers)}ê°œ ë…¼ë¬¸")
    
    # ìƒ˜í”Œ ì¶œë ¥
    if all_papers:
        print("\nğŸ“„ ìƒ˜í”Œ ë…¼ë¬¸:")
        sample = all_papers[0]
        print(f"   ì œëª©: {sample.get('title', 'N/A')[:60]}...")
        print(f"   ì €ì: {sample.get('author', 'N/A')}")
        print(f"   ì´ˆë¡: {sample.get('abstract', 'N/A')[:100]}...")
        print(f"   ì—°ë„: {sample.get('year', 'N/A')}")
    
    print("\n" + "="*70)
    print("âœ¨ ì™„ë£Œ!")
    print("="*70)


def main():
    """ë©”ì¸"""
    
    print("Excel â†’ JSON ë³€í™˜ê¸°")
    print()
    
    # í´ë” ì„ íƒ
    folder = input("Excel íŒŒì¼ì´ ìˆëŠ” í´ë” (ê¸°ë³¸: í˜„ì¬ í´ë”): ").strip() or "."
    
    # ì¶œë ¥ íŒŒì¼ëª…
    output = input("ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: papers_merged.json): ").strip() or "papers_merged.json"
    
    print()
    
    # ì²˜ë¦¬
    process_excel_files(folder_path=folder, output_file=output)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\n\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()